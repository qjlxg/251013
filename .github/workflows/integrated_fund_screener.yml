name: Extract and Save Fund Holdings and Analysis

on:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/integrated_fund_screener.yml'
      - 'integrated_fund_screener.py'
  
  schedule:
    - cron: '0 */3 * * *'  # 每 3 小时运行一次
  
  workflow_dispatch:

jobs:
  extract-data:
    env:
      TZ: Asia/Shanghai
      
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install pandas requests beautifulsoup4 numpy lxml

      - name: Run the data extraction and analysis script
        run: python integrated_fund_screener.py

      - name: Commit and push the new data and analysis files
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          files=(
            "fund_rankings.csv"
            "recommended_cn_funds.csv"
            "merged_funds.csv"
            "data/risk_metrics_*.json"
            "data/fund_managers_*.json"
            "failed_funds.txt"
          )
          
          for file in "${files[@]}"; do
            if ls $file 2>/dev/null; then
              git add $file
              git commit -m "Automated: Update $file" || true
            else
              echo "未找到 $file"
            fi
          done
          
          if git diff --cached --exit-code; then
            echo "没有新的数据文件需要推送。"
          else
            git push
            echo "已成功推送新的数据文件。"
          fi
